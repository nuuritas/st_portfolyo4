{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tqdm\n",
    "# !pip install lxml\n",
    "# !pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "import concurrent.futures\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fintables Sektörler ve Şirketler Güncelleniyor\n",
      "Fintables Sektörler ve Şirketler Güncellendi\n"
     ]
    }
   ],
   "source": [
    "def convert_sector_wide(data, sector_name):\n",
    "    rename_dict = {\n",
    "        \"Sektör Ortalamaları\": \"Metrics\",\n",
    "        \"F/K\": \"fk\",\n",
    "        \"PD/DD\": \"pd_dd\",\n",
    "        \"FD/FAVÖK\": \"fd_favok\"\n",
    "    }\n",
    "    \n",
    "    data = data.rename(columns=rename_dict)\n",
    "\n",
    "    \n",
    "    new_columns = {\n",
    "        \"BIST 100\": \"bist100\",\n",
    "        \"Aritmetik Ortalama\": \"ao\",\n",
    "        \"Ağırlıklı Ortalama\": \"wo\",\n",
    "        \"Medyan\": \"median\"\n",
    "    }\n",
    "\n",
    "    \n",
    "    wide_df = pd.DataFrame()\n",
    "    wide_df['sector_name'] = [sector_name]\n",
    "\n",
    "    for metric, prefix in new_columns.items():\n",
    "        for column in ['fk', 'pd_dd', 'fd_favok']:\n",
    "            col_name = f\"{prefix}_{column}\"\n",
    "            if sector_name == 'bankacilik' and column == 'fd_favok':\n",
    "                wide_df[col_name] = np.nan\n",
    "            else:\n",
    "                wide_df[col_name] = data[data['Metrics'] == metric][column].values\n",
    "\n",
    "    return wide_df\n",
    "\n",
    "def convert_piyasa_degeri(value):\n",
    "    value = value.replace('₺', '').strip()\n",
    "    if 'mr' in value:\n",
    "        value = float(value.replace('mr', '')) * 1e3  # convert to billion\n",
    "    elif 'mn' in value:\n",
    "        value = float(value.replace('mn', ''))  # convert to million\n",
    "    return value\n",
    "\n",
    "def get_sector(sector_name):\n",
    "\n",
    "    headers = {\n",
    "        'authority': 'fintables.com',\n",
    "        'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',\n",
    "        'accept-language': 'en-US,en;q=0.9,tr;q=0.8,tr-TR;q=0.7',\n",
    "        'cache-control': 'no-cache',\n",
    "        'cookie': '_gid=GA1.2.50961081.1690710140; _gcl_au=1.1.518997462.1690710149; auth-token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0b2tlbl90eXBlIjoiYWNjZXNzIiwiZXhwIjoyMTIyNzEwMTk3LCJpYXQiOjE2OTA3MTAxOTcsImp0aSI6IjQ2NGI0YTIxYjY3ZjQ3ZDY4MmEwYjg5NWE3ZjlkMWE4IiwidXNlcl9pZCI6MTEyNzMzfQ.Bh3945i5RjYHblFOyoN_e9oqVmQcOUukFo8GqXp5wtg; _gat_UA-72451211-3=1; _ga=GA1.2.1134893438.1690710140; _ga_22JQCWWZZJ=GS1.1.1690710149.1.1.1690711335.20.0.0',\n",
    "        'dnt': '1',\n",
    "        'pragma': 'no-cache',\n",
    "        'sec-ch-ua': '\"Not.A/Brand\";v=\"8\", \"Chromium\";v=\"114\", \"Google Chrome\";v=\"114\"',\n",
    "        'sec-ch-ua-mobile': '?0',\n",
    "        'sec-ch-ua-platform': '\"macOS\"',\n",
    "        'sec-fetch-dest': 'document',\n",
    "        'sec-fetch-mode': 'navigate',\n",
    "        'sec-fetch-site': 'same-origin',\n",
    "        'sec-fetch-user': '?1',\n",
    "        'upgrade-insecure-requests': '1',\n",
    "        'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36'\n",
    "    }\n",
    "\n",
    "    response = requests.get(f'https://fintables.com/sektorler/{sector_name}', headers=headers)\n",
    "\n",
    "    # The content of the response\n",
    "    from bs4 import BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    sektor_ozet = soup.find_all('table', class_=\"min-w-full\")[0]\n",
    "    sektor_ozet2 = str(sektor_ozet).replace(\".\",\"\").replace(',', '.')\n",
    "    sektor_ozet_df = pd.read_html(str(sektor_ozet2))[0]\n",
    "    sektor_ozet_wide = convert_sector_wide(sektor_ozet_df, sector_name)\n",
    "    \n",
    "    my_table = soup.find_all('table', class_=\"min-w-full\")[1]\n",
    "    my_table2 = str(my_table).replace(\".\",\"\").replace(',', '.')\n",
    "    df = pd.read_html(str(my_table2))[0]\n",
    "    \n",
    "    df['Piyasa Değeri'] = df['Piyasa Değeri'].apply(convert_piyasa_degeri)\n",
    "    #df['Piyasa Değeri'] = df['Piyasa Değeri'].astype(int)\n",
    "    df[\"sector\"] = sector_name\n",
    "\n",
    "    return sektor_ozet_wide, df\n",
    "\n",
    "def get_sector_multiple(sector_names):\n",
    "    ozet_list = []\n",
    "    sirket_list = []\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        for sektor_ozet,tum_sirketler in executor.map(get_sector, sector_names):\n",
    "            try:\n",
    "                sirket_list.append(tum_sirketler)\n",
    "                ozet_list.append(sektor_ozet)\n",
    "            except Exception as e:\n",
    "                print(\"Error: \", e)\n",
    "    sirket_df = pd.concat(sirket_list, axis=0, ignore_index=True)\n",
    "    ozet_df = pd.concat(ozet_list, axis=0, ignore_index=True)\n",
    "\n",
    "    sirket_df['Şirket Kodu'] = sirket_df['Şirket Kodu'].str[:-7]\n",
    "    # sirket_df['Piyasa Değeri'] = sirket_df['Piyasa Değeri'].astype(float)\n",
    "\n",
    "    sirket_df.columns = ['sirket_kodu', 'piyasa_degeri', 'fk', 'pd_dd', 'fd_favok', 'sector']\n",
    "    return ozet_df, sirket_df\n",
    "\n",
    "sector_names = json.load(open('../data/json/sector_names.json',encoding=\"utf-8\"))\n",
    "print(\"Fintables Sektörler ve Şirketler Güncelleniyor\")\n",
    "ozet_df, sirket_df = get_sector_multiple(sector_names)\n",
    "print(\"Fintables Sektörler ve Şirketler Güncellendi\")\n",
    "\n",
    "all_tickers = list(sirket_df['sirket_kodu'].unique())\n",
    "all_tickers.append('XU100')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for ticker MEKAG: Expecting value: line 1 column 1 (char 0)\n",
      "Time taken for daily: 11.75 seconds. Number of ticker: 525, fetched tickers: 524\n",
      "Error for ticker MEKAG: Expecting value: line 1 column 1 (char 0)\n",
      "Time taken for hourly 11.61 seconds. Number of ticker: 525, fetched tickers: 523\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import concurrent.futures\n",
    "import time\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36 Edg/117.0.2045.47\",\n",
    "    \"authority\": \"www.foreks.com\",\n",
    "    \"method\": \"GET\",\n",
    "    \"path\": \"/api/historical/intraday?code=OFSYM.E.BIST&period=1440&last=100\",\n",
    "    \"scheme\": \"https\",\n",
    "    \"accept\": \"application/json, text/plain, */*\",\n",
    "    \"accept-encoding\": \"gzip, deflate, br\",\n",
    "    \"accept-language\": \"tr,en;q=0.9,en-GB;q=0.8,en-US;q=0.7\",\n",
    "    \"dnt\": \"1\",\n",
    "    \"sec-ch-ua\": '\"Microsoft Edge\";v=\"117\", \"Not;A=Brand\";v=\"8\", \"Chromium\";v=\"117\"',\n",
    "    \"sec-ch-ua-mobile\": \"?0\",\n",
    "    \"sec-ch-ua-platform\": '\"macOS\"',\n",
    "    \"sec-fetch-dest\": \"empty\",\n",
    "    \"sec-fetch-mode\": \"cors\",\n",
    "    \"sec-fetch-site\": \"same-origin\"\n",
    "}\n",
    "\n",
    "cookies = {\n",
    "    \"i18n_redirected\": \"tr\",\n",
    "    \"pId\": \"vneta0e861cc-3c89-46a1-b21f-e2a720aecdb6\",\n",
    "    \"userID\": \"c77e2b32-d867-4933-a07c-0b53060cb496\",\n",
    "    \"_clck\": \"1l4vxdg|2|ffb|0|1363\",\n",
    "    \"_tt_enable_cookie\": \"1\",\n",
    "    \"_ttp\": \"TKVHsdwxEB9IQRbZxQ4pxgyyOhr\",\n",
    "    \"_gcl_au\": \"1.1.361451387.1695674357\",\n",
    "    \"__hstc\": \"81955593.f363a4ecc33435f6b82cd4e5799267d2.1695674357108.1695674357108.1695674357108.1\",\n",
    "    \"hubspotutk\": \"f363a4ecc33435f6b82cd4e5799267d2\",\n",
    "    \"_ga_TT9Z16KG4K\": \"GS1.1.1695674355.1.1.1695676366.60.0.0\",\n",
    "    \"_gid\": \"GA1.2.608856078.1696528526\",\n",
    "    \"_gat_gtag_UA_82686003_1\": \"1\",\n",
    "    \"_ga\": \"GA1.1.2132465251.1695674347\",\n",
    "    \"CloudFront-Key-Pair-Id\": \"APKAIVVJE7R23ILHVNCQ\",\n",
    "    \"watchID\": \"64ff5efb-82a6-46ec-a3af-3a7bb788375a\",\n",
    "    \"token\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VybmFtZSI6ImZvcmVrcy5jb20iLCJwYXNzd29yZCI6InY0YSFLJTJSIiwiaWF0IjoxNjk2NTI4NTMxfQ.cqrKQwWqLhRgbgiIBi2byJ2PzGhi29g1OyeUS2eVxDo\",\n",
    "    \"_ga_4Y6C81V13E\": \"GS1.1.1696528525.2.1.1696528531.54.0.0\",\n",
    "    \"_ga_3HPQ6LZVLP\": \"GS1.1.1696528525.2.1.1696528531.54.0.0\",\n",
    "    \"CloudFront-Signature\": \"fuQXXzqf5sNtiusAcYqifeHzaCN~bebSRyjP7RrQctAg9UgBfRPH~UxjW92V4GVTd1wi4v3ah0ajEbrRuTjUVHUq60wLigcTJu-veyXhWPKPyEzVhecEhLZmSFTlp52nyyw4dVmV2Qa8Hjneb~wAjc0dpXE11BO7bS3W5p5a4-~Ah7hR5O86mM5kuv7qqiGm3IUXSLwZk3b6NqnKaZMY9-fTBhqNDszxmMFoCiGA8cAOY3u5xvTIriBiXpQvO63TCj0DNeltTBE49Gz~okJCtQUenEOd32rSpOQulg3nJiqczhM5njy3p7SICJPov0yd-f~~uFKP5mctV90f~U5KGg__\",\n",
    "    \"CloudFront-Policy\": \"eyJTdGF0ZW1lbnQiOiBbeyJSZXNvdXJjZSI6Imh0dHBzOi8vbmV3cy1jb250ZW50LmZvcmVrcy5jb20vKiIsIkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY5NjUzMjE0N319fV19\"\n",
    "}\n",
    "\n",
    "def fetch_data_daily(ticker):\n",
    "    try:\n",
    "        if ticker == 'XU100':\n",
    "            url = f\"https://www.foreks.com/api/historical/intraday?code={ticker}.I.BIST&period=1440&last=1440\"\n",
    "        else:\n",
    "            url = f\"https://www.foreks.com/api/historical/intraday?code={ticker}.E.BIST&period=1440&last=1440\"\n",
    "        response = requests.get(url, headers=headers, cookies=cookies)\n",
    "        \n",
    "        temp = pd.DataFrame(response.json())\n",
    "        temp[\"ticker\"] = ticker\n",
    "\n",
    "        return temp\n",
    "    except Exception as e:\n",
    "        print(f\"Error for ticker {ticker}: {e}\")\n",
    "        return None\n",
    "    \n",
    "def fetch_data_hourly(ticker):\n",
    "    try:\n",
    "        if ticker == 'XU100':\n",
    "            url = f\"https://www.foreks.com/api/historical/intraday?code={ticker}.I.BIST&period=60&last=1440\"\n",
    "        else:\n",
    "            url = f\"https://www.foreks.com/api/historical/intraday?code={ticker}.E.BIST&period=60&last=1440\"\n",
    "        response = requests.get(url, headers=headers, cookies=cookies)\n",
    "        \n",
    "        temp = pd.DataFrame(response.json())\n",
    "        temp[\"ticker\"] = ticker\n",
    "\n",
    "        return temp\n",
    "    except Exception as e:\n",
    "        print(f\"Error for ticker {ticker}: {e}\")\n",
    "        return None\n",
    "\n",
    "start = time.time()\n",
    "all_data_daily = pd.DataFrame()\n",
    "MAX_WORKERS = 10\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "    futures = [executor.submit(fetch_data_daily, ticker) for ticker in all_tickers]\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        data = future.result()\n",
    "        if data is not None:\n",
    "            all_data_daily = pd.concat([all_data_daily, data], axis=0, ignore_index=True)\n",
    "all_data_daily['date'] = pd.to_datetime(all_data_daily['d'], unit='ms') + pd.Timedelta(hours=3)\n",
    "print(f\"Time taken for daily: {time.time() - start:.2f} seconds. Number of ticker: {len(all_tickers)}, fetched tickers: {len(all_data_daily.ticker.unique())}\")\n",
    "\n",
    "start = time.time()\n",
    "all_data_hourly = pd.DataFrame()\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "    futures = [executor.submit(fetch_data_hourly, ticker) for ticker in all_tickers]\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        data = future.result()\n",
    "        if data is not None:\n",
    "            all_data_hourly = pd.concat([all_data_hourly, data], axis=0, ignore_index=True)\n",
    "\n",
    "all_data_hourly[\"date\"] = pd.to_datetime(all_data_hourly[\"d\"], unit='ms') + pd.Timedelta(hours=3)\n",
    "print(f\"Time taken for hourly {time.time() - start:.2f} seconds. Number of ticker: {len(all_tickers)}, fetched tickers: {len(all_data_hourly.ticker.unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_hourly.drop(columns=[\"d\",\"v\",\"a\",\"v\"], inplace=True)\n",
    "all_data_daily.drop(columns=[\"d\",\"v\",\"a\",\"w\",\"v\"], inplace=True)\n",
    "\n",
    "all_data_daily.columns = ['open', 'high', 'low', 'close', 'ticker', 'date']\n",
    "all_data_hourly.columns = ['open', 'high', 'low', 'close', 'ticker', 'date']\n",
    "\n",
    "# all_data_daily.to_parquet('../data/parquet/data_daily.parquet')\n",
    "# all_data_hourly.to_parquet('../data/parquet/data_hourly.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
